{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Danish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Danish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "C:\\Users\\Danish\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (1,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\Danish\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(n_samples / df) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using SGD classifier is : 0.6063907044299202\n",
      "Confusion matrix using SGD classifier is : [[212  24  37  25]\n",
      " [ 34 210  58  53]\n",
      " [ 56  48 234  36]\n",
      " [ 46  59  66 179]]\n",
      "f1 score using SGD classifier is : 0.606285690789388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danish\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "C:\\Users\\Danish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:229: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "C:\\Users\\Danish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:229: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "C:\\Users\\Danish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:239: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using MLP classifier is : 0.5882352941176471\n",
      "f1-score for MLP classifier is : 0.5884901228221464\n",
      "Confusion matrix using MLP classifier is : [[213  30  32  23]\n",
      " [ 45 190  58  62]\n",
      " [ 50  50 226  48]\n",
      " [ 44  62  63 181]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n- We need a much larger, relevant and correct set of training data to be able to reach human level performance. The dataset \\n  that we have provides description of a situation, and the responses of subjects here may be different than how they would \\n  have responded in the real world \\n- We need more robust metrics for evaluating the performance of models that can consider meaning and sentence structure\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the required packages\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import collections\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Setting the directory\n",
    "os.chdir('C:/Users/Danish/JupyterNotebooks/IntrotoAI/Homework/HW4')\n",
    "\n",
    "# Specifying columns as the data as extra columns in some rows\n",
    "column_names = ['conv_id', 'utterance_idx', 'context', 'prompt', 'speaker_idx', 'utterance', 'selfeval', 'tags']\n",
    "\n",
    "# Importing the datasets\n",
    "train = pd.read_csv('empatheticdialogues/train.csv', names = column_names)\n",
    "valid = pd.read_csv('empatheticdialogues/valid.csv', names = column_names)\n",
    "test = pd.read_csv('empatheticdialogues/test.csv', names = column_names)\n",
    "\n",
    "\n",
    "# Excluding the first row as it has column names\n",
    "train = train[1:]\n",
    "valid = valid[1:]\n",
    "test = test[1:]\n",
    "\n",
    "# Appending validation dataset to train dataset in order to increase the number of training data points\n",
    "data = train.append(valid)\n",
    "\n",
    "### Data ETL\n",
    "\n",
    "## 1. a.\n",
    "# Filtering out all rows where the sentiment (‘context’) is not in the list of aforementioned list of sentiments \n",
    "# i.e. {'sad', 'jealous', 'joyful', 'terrified'}.\n",
    "data_context_filt = data.loc[data['context'].isin(['sad', 'jealous', 'joyful', 'terrified'])]\n",
    "test_data_context_filt = test.loc[test['context'].isin(['sad', 'jealous', 'joyful', 'terrified'])]\n",
    "\n",
    "\n",
    "## 1. b.\n",
    "# synthesize your training attributes and labels \n",
    "# i.e. ‘utterance’ as the attributes and ‘context’ as the label\n",
    "train_data = data_context_filt[['utterance', 'context']] \n",
    "test_data = test_data_context_filt[['utterance', 'context']] \n",
    "\n",
    "# Creating list of utterances\n",
    "train_data_list = list(train_data['utterance'])\n",
    "test_data_list = list(test_data['utterance'])\n",
    "\n",
    "\n",
    "# Cleaning the dataset\n",
    "# Removing special characters and numbers\n",
    "train_data_list_cleaned = [re.sub('[^a-zA-Z\\n\\.]', ' ', string) for string in train_data_list]\n",
    "# Removing full stop\n",
    "train_data_list_cleaned = [string.replace(\".\", \"\") for string in train_data_list_cleaned]\n",
    "# Removing extra spaces from beginning and end\n",
    "train_data_list_cleaned = [string.strip() for string in train_data_list_cleaned]\n",
    "# Converting to lowercase\n",
    "train_data_list_cleaned = [string.lower() for string in train_data_list_cleaned]\n",
    "\n",
    "test_data_list_cleaned = [re.sub('[^a-zA-Z\\n\\.]', ' ', string) for string in test_data_list]\n",
    "test_data_list_cleaned = [string.replace(\".\", \"\") for string in test_data_list_cleaned]\n",
    "test_data_list_cleaned = [string.strip() for string in test_data_list_cleaned]\n",
    "test_data_list_cleaned = [string.lower() for string in test_data_list_cleaned]\n",
    "\n",
    "### 2\n",
    "## Converting the utterances into a sparse bag-of-words \n",
    "\n",
    "train_count_vectorizer = CountVectorizer()\n",
    "X = train_count_vectorizer.fit_transform(train_data_list_cleaned)\n",
    "encoding = X.toarray()\n",
    "# Converting counts to 1 and 0\n",
    "for arr in encoding:\n",
    "    arr[arr > 0] = 1\n",
    "\n",
    "### 3 \n",
    "## The shortcomings with the previous representation are as follows\n",
    "#    1. There are some words which are not useful in the model because they do not encode any useful information, like propositions. These words need to be removed to reduce the dimensions\n",
    "#    2. Some words repaeat across multiple training data points and are thus less useful in differentiating between classes. These words need to be given lesser weights  \n",
    "        \n",
    "# Getting the list of stopwords and appending additional words to it\n",
    "stopwords_list = list(set(stopwords.words('english')))\n",
    "stopwords_list.extend(['comma', ''])  \n",
    "\n",
    "# Removing the stopwords\n",
    "train_data_stop_removed = []\n",
    "for row in train_data_list_cleaned:\n",
    "    tokens_without_sw = [word for word in row.split(\" \") if not word in stopwords_list]\n",
    "    tokens_without_sw = \" \".join(tokens_without_sw)\n",
    "    train_data_stop_removed.append(tokens_without_sw)\n",
    "    \n",
    "    \n",
    "test_data_stop_removed = []\n",
    "for row in test_data_list_cleaned:\n",
    "    tokens_without_sw = [word for word in row.split(\" \") if not word in stopwords_list]\n",
    "    tokens_without_sw = \" \".join(tokens_without_sw)\n",
    "    test_data_stop_removed.append(tokens_without_sw)\n",
    "\n",
    "\n",
    "# Creating the bag of words encoding again  \n",
    "train_count_vectorizer = CountVectorizer()\n",
    "X_train = train_count_vectorizer.fit_transform(train_data_stop_removed)\n",
    "\n",
    "train_one_hot_encoding = X_train.toarray()\n",
    "\n",
    "for arr in train_one_hot_encoding:\n",
    "    arr[arr > 0] = 1\n",
    "    \n",
    "\n",
    "\n",
    "# Getting the labels\n",
    "train_labels_unique = list(train_data['context'].unique())\n",
    "label_mapper = {}\n",
    "num = 0\n",
    "for label in train_labels_unique:\n",
    "    label_mapper[label] = num\n",
    "    num += 1\n",
    "\n",
    "\n",
    "train_labels = list(train_data['context'])\n",
    "train_labels_encoded = []\n",
    "for label in train_labels:\n",
    "    train_labels_encoded.append(label_mapper[label])\n",
    "\n",
    "\n",
    "### 4. Normalization\n",
    "# Normalizing the training data using tfidf transformer \n",
    "train_tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "train_embedding_tfidf_transformer = train_tfidf_transformer.fit_transform(train_one_hot_encoding)\n",
    "\n",
    "\n",
    "### 5. Building an SGD Classifier\n",
    "\n",
    "# The error analysis must include the test accuracy, confusion matrix and a few misclassified examples and your thoughts on why those utterances were misclassified by the example.\n",
    "X_train = train_embedding_tfidf_transformer\n",
    "y_train = np.array(train_labels_encoded)\n",
    "clf = SGDClassifier(loss=\"modified_huber\", penalty=\"l2\", max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "# Using training data vocabulary on test data so that the features are consistent    \n",
    "test_count_vectorizer = CountVectorizer(vocabulary = train_count_vectorizer.get_feature_names())\n",
    "X_test = test_count_vectorizer.fit_transform(test_data_stop_removed)\n",
    "\n",
    "test_one_hot_encoding = X_test.toarray()\n",
    "\n",
    "for arr in test_one_hot_encoding:\n",
    "    arr[arr > 0] = 1\n",
    "\n",
    "# Normalizing the test data  \n",
    "test_tfidf_transformer = TfidfTransformer(smooth_idf=False,use_idf=True)\n",
    "test_embedding_tfidf_transformer = test_tfidf_transformer.fit_transform(test_one_hot_encoding)\n",
    "\n",
    "# Getting predictions on test data\n",
    "test_predicted_labels = clf.predict(test_embedding_tfidf_transformer)\n",
    "\n",
    "# Getting test labels\n",
    "labels_test = list(test_data['context'])\n",
    "labels_encoded_test = []\n",
    "for label in labels_test:\n",
    "    labels_encoded_test.append(label_mapper[label])\n",
    "labels_encoded_test = np.array(labels_encoded_test)\n",
    "\n",
    "print('Test accuracy using SGD classifier is :', np.mean(labels_encoded_test == test_predicted_labels))\n",
    "\n",
    "f1_score_vector = f1_score(labels_encoded_test, test_predicted_labels, average=None)\n",
    "\n",
    "print('Confusion matrix using SGD classifier is :', confusion_matrix(labels_encoded_test, test_predicted_labels))\n",
    "\n",
    "print('f1 score using SGD classifier is :', np.mean(f1_score_vector))\n",
    "\n",
    "# \n",
    "misclassified_cleaned = list(compress(test_data_list_cleaned, list(labels_encoded_test != test_predicted_labels)))\n",
    "misclassified_stop_removed = list(compress(test_data_stop_removed, list(labels_encoded_test != test_predicted_labels)))\n",
    "mapper_label = dict([(value, key) for key, value in label_mapper.items()])\n",
    "labels_test = [mapper_label[x] for x in labels_encoded_test]\n",
    "predicted_labels_test = [mapper_label[x] for x in test_predicted_labels]\n",
    "misclassified_actual = list(compress(labels_test, list(labels_encoded_test != test_predicted_labels)))\n",
    "misclassified_predicted = list(compress(predicted_labels_test, list(labels_encoded_test != test_predicted_labels)))\n",
    "df = pd.DataFrame(list(zip(misclassified_cleaned, misclassified_stop_removed, misclassified_actual, misclassified_predicted)), columns = ['cleaned', 'stop removed', 'actual', 'predicted'])\n",
    "\n",
    "# Thoughts on why some occurences are misclassified\n",
    "'''\n",
    "Example 1:\n",
    "actual utterance: 'oh no   what happened to it'\n",
    "utterance stop removed: 'oh happened'\n",
    "actual label: 'sad'\n",
    "predicted label: 'terrified'\n",
    "\n",
    "Comment: Here we do not have any word that conveys an emotion apart from 'oh' which can be either sad or terrified.\n",
    "         The original sentence without stop words removed would have been better to predict\n",
    "\n",
    "\n",
    "Example 2:\n",
    "actual utterance: 'thank you i appreciate that'\n",
    "utterance stop removed: 'thank appreciate'\n",
    "actual label: 'sad'\n",
    "predicted label: 'joyful'\n",
    "\n",
    "Comment: Here the predicted label is correct and it seems that the labelling is wrong\n",
    "'''\n",
    "\n",
    "### 6. Classifier using pretrained embeddings\n",
    "\n",
    "# Tokenizing the data\n",
    "train_tokens = [nltk.word_tokenize(sentences) for sentences in train_data_stop_removed]\n",
    "train_y = np.array(train_labels_encoded)\n",
    "\n",
    "test_tokens = [nltk.word_tokenize(sentences) for sentences in test_data_stop_removed]\n",
    "test_y = np.array(labels_encoded_test)\n",
    "\n",
    "# Loading the pretrained word2vec model from Google\n",
    "# https://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./model/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "\n",
    "# Reference for the class code below\n",
    "# http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "\n",
    "# Creating features from word embeddings\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = model.wv.vector_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = collections.defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n",
    "\n",
    "                \n",
    "# Creating a pipeline for word2vec Vectorizer and MLP Classifier              \n",
    "clf_tfidf_mlp = Pipeline([\n",
    "    (\"word2vec Vectorizer\", TfidfEmbeddingVectorizer(w2v)),\n",
    "    (\"MLP Classifier\", MLPClassifier(solver = 'adam', alpha = 1e-5, hidden_layer_sizes=(100,100,100), random_state=1, max_iter=500, learning_rate='adaptive', learning_rate_init=0.01))\n",
    "    ])\n",
    "\n",
    "# Fitting the model\n",
    "X = train_tokens\n",
    "y = train_labels_encoded\n",
    "clf_tfidf_mlp.fit(X, y)\n",
    "\n",
    "\n",
    "test_X = test_tokens\n",
    "\n",
    "pred_y = clf_tfidf_mlp.predict(test_X)\n",
    "\n",
    "print('Test accuracy using MLP classifier is :', np.mean(test_y == pred_y))\n",
    "\n",
    "f1_score_vector = f1_score(test_y, pred_y, average=None)\n",
    "\n",
    "print('f1-score for MLP classifier is :', np.mean(f1_score_vector))\n",
    "\n",
    "print('Confusion matrix using MLP classifier is :', confusion_matrix(test_y, pred_y))\n",
    "\n",
    "'''\n",
    "Read the paper at https://arxiv.org/pdf/1811.00207.pdf and answer the following questions:\n",
    "1) What does this paper mean by \"fine-tuning\" results? How might you use such fine-tuning in building an empathetic chatbot?\n",
    "2) What properties of the transformer architecture make it well suited for this application?\n",
    "3) Explain the metrics used to evaluate performance in Table 1 (P@1,100, AVG-BLEU, and PPL).\n",
    "4) Which of the metrics do you think provides the best measure of performance of empathic systems and why?\n",
    "5) Based on table 1 and 2, and your reading of the paper, what do you think would help the system get to human-level performance?\n",
    "'''\n",
    "\n",
    "### 1 \n",
    "'''\n",
    "Fine-tuning the results means training a pre-trained model on the data generated by the chatbot \n",
    "so that it can produce more contextual results. For example, BERT is a model pre-trained on English Wikipedia. \n",
    "In this paper, BERT is first trained on Reddit conversations and then fine-tuned on the actual dataset. \n",
    "The pre-training helps because a large amount of data is used for training deep learning models \n",
    "whereas the chatbot may not have produced a lot of data initially. \n",
    "Hence, the idea is to use a pre-trained model and then improve its parameters by training again on the chatbot data. \n",
    "'''\n",
    "\n",
    "### 2\n",
    "'''\n",
    "1. Transformer models are attention based models, that is, they see the entire sentence as a whole unlike RNN \n",
    "where the sentence is processed one word at each time step. Transformer sees all words simultaneously and there is no \n",
    "backpropagation through time. They capture long term dependencies easily because they see all words at once.\n",
    "\n",
    "2. Attention models solve both alignment and translation problem. Alignment is the problem in machine translation that \n",
    "identifies which parts of the input sequence are relevant to each word in the output. Rranslation is the process of \n",
    "using the relevant information to select the appropriate output.\n",
    "'''\n",
    "\n",
    "### 3\n",
    "'''\n",
    "P@1,100:\n",
    "It is the accuracy of choosing the correct responses out of a hundred randomly selected examples in the test \n",
    "set. Here the actual response is included in the candidates.\n",
    "\n",
    "AVG-BLEU: \n",
    "- The idea behind BLEU is the closer a machine translation is to a professional human translation, the better it is. BLEU \n",
    "  score measures the difference between human and machine translation output\n",
    "- It looks at the presence or absence of particular words, as well as the ordering and the degree of distortion, that is, \n",
    "  how much they actually are separated in the output\n",
    "- Its evaluation requires two inputs, a numerical translation closeness metric and a corpus of human reference translations.\n",
    "  BLEU averages out various metrics using an n-gram method\n",
    "- The result is typically measured on a 0 to 1 scale, with 1 representing perfect translation\n",
    "\n",
    "PPL:\n",
    "- Perplexity measures how well a model predicts a sample\n",
    "- Perplexity of a random variable X may be defined as the perplexity of the distribution over its possible values x\n",
    "- A low perplexity indicates the probability distribution is good at predicting the sample\n",
    "'''\n",
    "\n",
    "### 4\n",
    "''' \n",
    "BLEU is useful because it is ubiquitous, which makes it easy to compare your model to benchmarks on the same task. \n",
    "However, BLEU doesn’t consider meaning and it doesn’t directly consider sentence structure.\n",
    "Perplexity is often used as a quality measure for language models. Language model perplexity has been used for \n",
    "domain adaptation. \n",
    "We should use both these metrics to measure the performance of emphatic systems as they both have their own pros and cons.\n",
    "'''\n",
    "\n",
    "### 5\n",
    "'''\n",
    "- We need a much larger, relevant and correct set of training data to be able to reach human level performance. The dataset \n",
    "  that we have provides description of a situation, and the responses of subjects here may be different than how they would \n",
    "  have responded in the real world \n",
    "- We need more robust metrics for evaluating the performance of models that can consider meaning and sentence structure\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
